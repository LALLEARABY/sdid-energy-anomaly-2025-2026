# G4 - Anomaly Detection Engine & ROI Calculator

**Projet SDID 2025/2026 - Groupe 4**  
Syst√®me de D√©tection d'Anomalies en Temps R√©el pour la Surveillance √ânerg√©tique

---

## üìã Description

Ce module impl√©mente un **moteur de d√©tection d'anomalies** en temps r√©el utilisant l'algorithme **Isolation Forest** pour identifier les comportements anormaux dans les donn√©es de consommation √©lectrique. Il calcule √©galement le **ROI (Return on Investment)** du syst√®me.

### Fonctionnalit√©s principales

1. **Synchronisation avec G3** : Utilise les param√®tres de normalisation et l'ACP fournis par le Groupe 3
2. **Entra√Ænement du mod√®le** : Isolation Forest sur donn√©es historiques propres
3. **Scoring en temps r√©el** : Moteur "consommateur" qui interroge PostgreSQL r√©guli√®rement
4. **Alertes automatiques** : Mise √† jour du champ `is_anomaly` dans la base de donn√©es
5. **Calcul du ROI** : √âvaluation financi√®re (pannes √©vit√©es vs fausses alertes)
6. **Statistiques de performance** : M√©triques transmises au Groupe 1

---

## üèóÔ∏è Architecture

```
G4_Anomaly_Detection/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py              # Configuration (DB, mod√®le, ROI)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database.py            # Connexion PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py        # Chargement param√®tres G3 + transformation
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py    # Mod√®le Isolation Forest
‚îÇ   ‚îú‚îÄ‚îÄ scoring_engine.py      # Moteur de scoring temps r√©el
‚îÇ   ‚îî‚îÄ‚îÄ roi_calculator.py      # Calcul du ROI
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ g3_scaler.pkl          # Scaler du G3 (√† r√©cup√©rer)
‚îÇ   ‚îú‚îÄ‚îÄ g3_pca.pkl             # PCA du G3 (√† r√©cup√©rer)
‚îÇ   ‚îî‚îÄ‚îÄ anomaly_detector.pkl   # Mod√®le entra√Æn√©
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ score_distribution.png # Visualisation des scores
‚îÇ   ‚îî‚îÄ‚îÄ roi_report.txt         # Rapport ROI
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ analysis.ipynb         # Analyses exploratoires
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py              # Tests unitaires
‚îú‚îÄ‚îÄ .env                       # Variables d'environnement (√† cr√©er)
‚îú‚îÄ‚îÄ .env.example               # Exemple de configuration
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances Python
‚îú‚îÄ‚îÄ train_model.py             # Script d'entra√Ænement
‚îî‚îÄ‚îÄ README.md                  # Ce fichier
```

---

## üöÄ Installation




---

## üê≥ Utilisation avec Docker

### D√©marrage rapide
```bash
# Depuis la racine du projet
docker-compose up -d g4_anomaly_detection

# V√©rifier les logs
docker logs -f g4_anomaly_detection

# Voir les statistiques
docker exec -it sdid_postgres psql -U sdid_user -d sdid_db -c "SELECT COUNT(*) as total, SUM(CASE WHEN is_anomaly THEN 1 ELSE 0 END) as anomalies FROM power_consumption;"
```

### Services Docker disponibles

- **g4_anomaly_detection** : Scoring engine en mode continu
- **g4_roi** : Calculateur de ROI (lancer avec `docker-compose run --rm g4_roi`)

### Variables d'environnement Docker

Les variables sont configur√©es dans `docker-compose.yml` :
- `DB_HOST=db` (nom du service PostgreSQL)
- `DB_PORT=5432`
- `ANOMALY_THRESHOLD=-0.5468`
- `SCORING_INTERVAL=60`





### 1. Pr√©requis

- Python 3.8+
- PostgreSQL (fourni par G2)
- Param√®tres G3 (scaler + PCA)

### 2. Installation des d√©pendances

```bash
cd G4_Anomaly_Detection
pip install -r requirements.txt
```

### 3. Configuration

Cr√©ez un fichier `.env` √† partir de `.env.example` :

```bash
cp .env.example .env
```

Modifiez `.env` avec vos param√®tres :

```env
# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=power_consumption_db
DB_USER=votre_user
DB_PASSWORD=votre_password

# Model
ANOMALY_THRESHOLD=-0.5
CONTAMINATION=0.01
N_ESTIMATORS=100

# ROI
COST_PREVENTED_FAILURE=5000
COST_FALSE_ALARM=50
ENERGY_COST_PER_KWH=0.15
```

### 4. R√©cup√©ration des param√®tres G3

Placez les fichiers du Groupe 3 dans le dossier `models/` :

```bash
# √Ä r√©cup√©rer depuis le d√©p√¥t G3
models/g3_scaler.pkl
models/g3_pca.pkl
```

---

## üìä Utilisation

### √âtape 1 : Entra√Ænement du mod√®le

```bash
python train_model.py
```

Options disponibles :
```bash
python train_model.py --samples 10000  # Limiter √† 10k √©chantillons
python train_model.py --algorithm lof  # Utiliser LOF au lieu d'Isolation Forest
python train_model.py --validate       # Valider apr√®s entra√Ænement
```

**Sortie attendue** :
- Mod√®le sauvegard√© : `models/anomaly_detector.pkl`
- Graphique : `docs/score_distribution.png`
- Logs avec statistiques d'entra√Ænement

### √âtape 2 : Scoring en temps r√©el

**Mode continu** (recommand√© pour production) :
```bash
python src/scoring_engine.py --mode continuous --interval 60
```

**Mode unique** (pour tests ou cron) :
```bash
python src/scoring_engine.py --mode once
```

**Sortie attendue** :
- Mise √† jour automatique de la colonne `is_anomaly` en base
- Logs des anomalies d√©tect√©es en temps r√©el
- Statistiques de performance

### √âtape 3 : Calcul du ROI

```bash
python src/roi_calculator.py
```

**Sortie attendue** :
- Rapport d√©taill√© : `docs/roi_report.txt`
- Affichage console des m√©triques financi√®res

---

## üîß D√©veloppement

### Tests unitaires

```bash
pytest tests/
```

### Analyse exploratoire

Ouvrir le notebook Jupyter :
```bash
jupyter notebook notebooks/analysis.ipynb
```

### Ajuster le seuil d'anomalie

1. Observer `docs/score_distribution.png`
2. Modifier `ANOMALY_THRESHOLD` dans `.env`
3. Re-ex√©cuter le scoring engine

---

## üìà M√©triques cl√©s

Le syst√®me fournit les m√©triques suivantes (transmises √† G1) :

### M√©triques de d√©tection
- Taux d'anomalies d√©tect√©es
- Distribution des scores
- Fr√©quence des alertes

### M√©triques financi√®res (ROI)
- Co√ªt total du syst√®me
- B√©n√©fices (pannes √©vit√©es + √©conomies d'√©nergie)
- ROI en %
- P√©riode de retour sur investissement
- Ratio b√©n√©fices/co√ªts

### Exemples de r√©sultats

```
Total records analyzed:    5,000
Anomalies detected:        ~300
Anomaly rate:              ~6%

Anomaly threshold:         -0.5468 (5th percentile)


Top anomalies detected:
- Overconsumption: 5.4-5.9 kW (vs normal 2-4 kW)
- Underconsumption: 1.0-1.6 kW
- Voltage anomalies: 235-245 V (vs normal 220-240 V)



Energy cost savings:       $1,875.00
Value of prevention:       $218,750.00
False alarm cost:          $312.50

NET BENEFIT:               $210,312.50
ROI:                       2003.12%
Payback period:            18 days
```

---

## üîÑ Int√©gration avec les autres groupes

### D√©pendances en entr√©e

| Groupe | Fichier(s) requis | Description |
|--------|------------------|-------------|
| **G2** | Base PostgreSQL | Table `power_consumption` avec flux temps r√©el |
| **G3** | `g3_scaler.pkl`<br>`g3_pca.pkl` | Param√®tres de normalisation et ACP |

### Sorties vers les autres groupes

| Groupe | Livrable | Description |
|--------|----------|-------------|
| **G1** | Mini-rapport technique | M√©thodologie + r√©sultats + code |
| **G1** | Statistiques | M√©triques de performance JSON/CSV |
| **G5** | Colonne `is_anomaly` | Champ mis √† jour en temps r√©el pour dashboard |

---

## üõ†Ô∏è R√©solution de probl√®mes

### Probl√®me : "G3 parameters not found"
**Solution** : V√©rifier que `models/g3_scaler.pkl` et `models/g3_pca.pkl` existent. Si non, contacter G3.

### Probl√®me : "Failed to connect to database"
**Solution** : 
1. V√©rifier que PostgreSQL est d√©marr√© (G2)
2. V√©rifier les credentials dans `.env`
3. Tester : `python src/database.py`

### Probl√®me : Trop de fausses alertes
**Solution** : 
1. Analyser `docs/score_distribution.png`
2. Augmenter `ANOMALY_THRESHOLD` dans `.env` (ex: -0.3 au lieu de -0.5)
3. Re-ex√©cuter le scoring

### Probl√®me : Pas assez d'anomalies d√©tect√©es
**Solution** : 
1. Diminuer `ANOMALY_THRESHOLD` (ex: -0.7)
2. Augmenter `CONTAMINATION` dans `.env`

---

## üìù Livrables pour G1

### 1. Code
- ‚úÖ D√©p√¥t GitHub avec branche `g4-anomaly-detection`
- ‚úÖ Code comment√© et structur√©
- ‚úÖ Tests unitaires

### 2. Documentation
- ‚úÖ README complet (ce fichier)
- ‚úÖ Mini-rapport technique (docs/technical_report.md)
- ‚úÖ Rapport ROI (docs/roi_report.txt)

### 3. R√©sultats
- ‚úÖ Mod√®le entra√Æn√© (`models/anomaly_detector.pkl`)
- ‚úÖ Graphiques de distribution
- ‚úÖ Statistiques de performance (JSON)

---

## üë• Contributeurs

**Groupe 4 - SDID 2025/2026**

- [2309 23644 23658] - Lead Developer
  - D√©veloppement du mod√®le Isolation Forest
  - Moteur de scoring temps r√©el
  - Calcul du ROI et m√©triques financi√®res
  - Int√©gration Docker et CI/CD
---

## üìö R√©f√©rences

- Dataset UCI : "Individual Household Electric Power Consumption"
- Algorithme : Isolation Forest (Liu et al., 2008)
- Alternative : Local Outlier Factor (Breunig et al., 2000)

---

## üìß Contact

Pour toute question technique, contacter le Groupe 4 via le canal Slack `#g4-anomalies` ou ouvrir une issue sur GitHub.

---

**Derni√®re mise √† jour** : Janvier 2026

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G4 - Anomaly Detection Analysis\n",
    "## Exploratory Data Analysis and Model Evaluation\n",
    "\n",
    "**Project**: SDID 2025/2026  \n",
    "**Group**: G4 - Anomaly Detection & ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from src.database import DatabaseConnection\n",
    "from src.preprocessor import DataPreprocessor\n",
    "from src.anomaly_detector import AnomalyDetector\n",
    "from src.roi_calculator import ROICalculator\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "db = DatabaseConnection()\n",
    "db.connect()\n",
    "\n",
    "# Load data\n",
    "df = db.get_historical_data(limit=10000)\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of key features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].hist(df['global_active_power'], bins=50, alpha=0.7)\n",
    "axes[0, 0].set_title('Global Active Power Distribution')\n",
    "axes[0, 0].set_xlabel('Power (kW)')\n",
    "\n",
    "axes[0, 1].hist(df['voltage'], bins=50, alpha=0.7, color='orange')\n",
    "axes[0, 1].set_title('Voltage Distribution')\n",
    "axes[0, 1].set_xlabel('Voltage (V)')\n",
    "\n",
    "axes[1, 0].hist(df['global_intensity'], bins=50, alpha=0.7, color='green')\n",
    "axes[1, 0].set_title('Global Intensity Distribution')\n",
    "axes[1, 0].set_xlabel('Intensity (A)')\n",
    "\n",
    "axes[1, 1].hist(df['global_reactive_power'], bins=50, alpha=0.7, color='red')\n",
    "axes[1, 1].set_title('Global Reactive Power Distribution')\n",
    "axes[1, 1].set_xlabel('Power (kVAR)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing (G3 Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load G3 preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Try to load G3 parameters\n",
    "if not preprocessor.load_g3_parameters():\n",
    "    print(\"G3 parameters not found, fitting on current data...\")\n",
    "    preprocessor.fit_default(df)\n",
    "\n",
    "# Transform data\n",
    "X_transformed = preprocessor.transform(df)\n",
    "print(f\"Transformed shape: {X_transformed.shape}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nPCA Components:\")\n",
    "preprocessor.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA components\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.scatter(X_transformed[:, 0], X_transformed[:, 1], alpha=0.3, s=1)\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC2')\n",
    "ax1.set_title('PC1 vs PC2')\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.scatter(X_transformed[:, 0], X_transformed[:, 2], alpha=0.3, s=1)\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC3')\n",
    "ax2.set_title('PC1 vs PC3')\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.scatter(X_transformed[:, 1], X_transformed[:, 2], alpha=0.3, s=1)\n",
    "ax3.set_xlabel('PC2')\n",
    "ax3.set_ylabel('PC3')\n",
    "ax3.set_title('PC2 vs PC3')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Anomaly Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "detector = AnomalyDetector(algorithm='isolation_forest')\n",
    "detector.train(X_transformed)\n",
    "\n",
    "# Predict on same data\n",
    "scores, predictions = detector.predict(X_transformed)\n",
    "\n",
    "print(f\"Anomalies detected: {sum(predictions)}/{len(predictions)} ({sum(predictions)/len(predictions)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(scores, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(detector.threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {detector.threshold}')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(scores[predictions], bins=30, alpha=0.7, color='red', label='Anomalies')\n",
    "plt.hist(scores[~predictions], bins=30, alpha=0.7, color='blue', label='Normal')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Score Distribution by Class')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomalies in PCA space\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# PC1 vs PC2\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.scatter(X_transformed[~predictions, 0], X_transformed[~predictions, 1], \n",
    "           alpha=0.3, s=10, c='blue', label='Normal')\n",
    "ax1.scatter(X_transformed[predictions, 0], X_transformed[predictions, 1], \n",
    "           alpha=0.8, s=50, c='red', marker='x', label='Anomaly')\n",
    "ax1.set_xlabel('PC1')\n",
    "ax1.set_ylabel('PC2')\n",
    "ax1.set_title('Anomalies in PC1-PC2 Space')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# PC1 vs PC3\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.scatter(X_transformed[~predictions, 0], X_transformed[~predictions, 2], \n",
    "           alpha=0.3, s=10, c='blue', label='Normal')\n",
    "ax2.scatter(X_transformed[predictions, 0], X_transformed[predictions, 2], \n",
    "           alpha=0.8, s=50, c='red', marker='x', label='Anomaly')\n",
    "ax2.set_xlabel('PC1')\n",
    "ax2.set_ylabel('PC3')\n",
    "ax2.set_title('Anomalies in PC1-PC3 Space')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# PC2 vs PC3\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.scatter(X_transformed[~predictions, 1], X_transformed[~predictions, 2], \n",
    "           alpha=0.3, s=10, c='blue', label='Normal')\n",
    "ax3.scatter(X_transformed[predictions, 1], X_transformed[predictions, 2], \n",
    "           alpha=0.8, s=50, c='red', marker='x', label='Anomaly')\n",
    "ax3.set_xlabel('PC2')\n",
    "ax3.set_ylabel('PC3')\n",
    "ax3.set_title('Anomalies in PC2-PC3 Space')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomaly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to dataframe\n",
    "df['anomaly_score'] = scores\n",
    "df['is_anomaly'] = predictions\n",
    "\n",
    "# Compare normal vs anomalous data\n",
    "print(\"Normal data statistics:\")\n",
    "print(df[~df['is_anomaly']][['global_active_power', 'voltage', 'global_intensity']].describe())\n",
    "\n",
    "print(\"\\nAnomalous data statistics:\")\n",
    "print(df[df['is_anomaly']][['global_active_power', 'voltage', 'global_intensity']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 anomalies\n",
    "top_anomalies = df[df['is_anomaly']].nsmallest(10, 'anomaly_score')\n",
    "print(\"Top 10 Most Anomalous Records:\")\n",
    "top_anomalies[['timestamp', 'global_active_power', 'voltage', 'anomaly_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ROI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROI\n",
    "roi_calc = ROICalculator()\n",
    "\n",
    "if roi_calc.connect():\n",
    "    # Get complete data\n",
    "    df_roi = roi_calc.get_anomaly_data()\n",
    "    \n",
    "    if len(df_roi) > 0:\n",
    "        analysis = roi_calc.calculate_roi(df_roi, system_cost=10000)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ROI ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        roi = analysis['roi_summary']\n",
    "        print(f\"System Cost:        ${roi['system_cost']:,.2f}\")\n",
    "        print(f\"Total Benefits:     ${roi['total_benefits']:,.2f}\")\n",
    "        print(f\"Net Benefit:        ${roi['net_benefit']:,.2f}\")\n",
    "        print(f\"ROI:                {roi['roi_percentage']:.2f}%\")\n",
    "        print(f\"Payback Period:     {roi['payback_period_days']:.0f} days\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    roi_calc.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Threshold Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds = np.linspace(-1.0, 0.0, 50)\n",
    "anomaly_rates = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    is_anom = scores < thresh\n",
    "    anomaly_rates.append(sum(is_anom) / len(is_anom) * 100)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, anomaly_rates, linewidth=2)\n",
    "plt.axvline(detector.threshold, color='red', linestyle='--', \n",
    "           label=f'Current threshold: {detector.threshold}')\n",
    "plt.axhline(1, color='green', linestyle=':', alpha=0.5, label='1% anomaly rate')\n",
    "plt.axhline(5, color='orange', linestyle=':', alpha=0.5, label='5% anomaly rate')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Anomaly Rate (%)')\n",
    "plt.title('Threshold Sensitivity Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "detector.save_model('../models/anomaly_detector.pkl')\n",
    "print(\"✓ Model saved\")\n",
    "\n",
    "# Save analysis results\n",
    "results = {\n",
    "    'total_records': len(df),\n",
    "    'anomalies_detected': int(sum(predictions)),\n",
    "    'anomaly_rate': float(sum(predictions)/len(predictions)*100),\n",
    "    'threshold': float(detector.threshold),\n",
    "    'score_mean': float(scores.mean()),\n",
    "    'score_std': float(scores.std())\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../docs/analysis_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"✓ Results saved to docs/analysis_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "db.disconnect()\n",
    "print(\"\\n✓ Analysis complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
